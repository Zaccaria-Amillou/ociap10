{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projet 10: Application de recommandation de contenu\n",
    "### Partie 2: Modèlisation \n",
    "Dans ce notebook on vas procéder à effectuer la modélisation des nos données pour mettre en place une systeme de recommandation du contenu.\n",
    "Nous allons utiliser deux approches principales:\n",
    "- Content-based filtering\n",
    "- Collaborative-based filtering\n",
    "\n",
    "Nous allons nous appuyer sur la libraries [Surpise](https://surpriselib.com/) pour mettre en place nos modèles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Import des libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from math import floor\n",
    "import numpy as np\n",
    "\n",
    "import surprise\n",
    "from surprise import SVD, Dataset, Reader, KNNBasic, KNNWithMeans\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import train_test_split\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Import des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant nous allons procéder aves l'importations des libraries que nous allons utiliser pour la modèlisation et puis on vas importer les fichiers des données que nous allons utiliser comme base pour les modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/raw/globocom/\"\n",
    "clicks_path= \"../data/raw/globocom/clicks/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Import fichier avec metadonnées des articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1513144419000</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1405341936000</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1408667706000</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1408468313000</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1407071171000</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  category_id  created_at_ts  publisher_id  words_count\n",
       "0           0            0  1513144419000             0          168\n",
       "1           1            1  1405341936000             0          189\n",
       "2           2            1  1408667706000             0          250\n",
       "3           3            1  1408468313000             0          230\n",
       "4           4            1  1407071171000             0          162"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df = pd.read_csv(data_path + 'articles_metadata.csv')\n",
    "articles_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Import fichiers avec embeddings des articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>emb_7</th>\n",
       "      <th>emb_8</th>\n",
       "      <th>emb_9</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_240</th>\n",
       "      <th>emb_241</th>\n",
       "      <th>emb_242</th>\n",
       "      <th>emb_243</th>\n",
       "      <th>emb_244</th>\n",
       "      <th>emb_245</th>\n",
       "      <th>emb_246</th>\n",
       "      <th>emb_247</th>\n",
       "      <th>emb_248</th>\n",
       "      <th>emb_249</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.161183</td>\n",
       "      <td>-0.957233</td>\n",
       "      <td>-0.137944</td>\n",
       "      <td>0.050855</td>\n",
       "      <td>0.830055</td>\n",
       "      <td>0.901365</td>\n",
       "      <td>-0.335148</td>\n",
       "      <td>-0.559561</td>\n",
       "      <td>-0.500603</td>\n",
       "      <td>0.165183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321248</td>\n",
       "      <td>0.313999</td>\n",
       "      <td>0.636412</td>\n",
       "      <td>0.169179</td>\n",
       "      <td>0.540524</td>\n",
       "      <td>-0.813182</td>\n",
       "      <td>0.286870</td>\n",
       "      <td>-0.231686</td>\n",
       "      <td>0.597416</td>\n",
       "      <td>0.409623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.523216</td>\n",
       "      <td>-0.974058</td>\n",
       "      <td>0.738608</td>\n",
       "      <td>0.155234</td>\n",
       "      <td>0.626294</td>\n",
       "      <td>0.485297</td>\n",
       "      <td>-0.715657</td>\n",
       "      <td>-0.897996</td>\n",
       "      <td>-0.359747</td>\n",
       "      <td>0.398246</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.487843</td>\n",
       "      <td>0.823124</td>\n",
       "      <td>0.412688</td>\n",
       "      <td>-0.338654</td>\n",
       "      <td>0.320787</td>\n",
       "      <td>0.588643</td>\n",
       "      <td>-0.594137</td>\n",
       "      <td>0.182828</td>\n",
       "      <td>0.397090</td>\n",
       "      <td>-0.834364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.619619</td>\n",
       "      <td>-0.972960</td>\n",
       "      <td>-0.207360</td>\n",
       "      <td>-0.128861</td>\n",
       "      <td>0.044748</td>\n",
       "      <td>-0.387535</td>\n",
       "      <td>-0.730477</td>\n",
       "      <td>-0.066126</td>\n",
       "      <td>-0.754899</td>\n",
       "      <td>-0.242004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454756</td>\n",
       "      <td>0.473184</td>\n",
       "      <td>0.377866</td>\n",
       "      <td>-0.863887</td>\n",
       "      <td>-0.383365</td>\n",
       "      <td>0.137721</td>\n",
       "      <td>-0.810877</td>\n",
       "      <td>-0.447580</td>\n",
       "      <td>0.805932</td>\n",
       "      <td>-0.285284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.740843</td>\n",
       "      <td>-0.975749</td>\n",
       "      <td>0.391698</td>\n",
       "      <td>0.641738</td>\n",
       "      <td>-0.268645</td>\n",
       "      <td>0.191745</td>\n",
       "      <td>-0.825593</td>\n",
       "      <td>-0.710591</td>\n",
       "      <td>-0.040099</td>\n",
       "      <td>-0.110514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271535</td>\n",
       "      <td>0.036040</td>\n",
       "      <td>0.480029</td>\n",
       "      <td>-0.763173</td>\n",
       "      <td>0.022627</td>\n",
       "      <td>0.565165</td>\n",
       "      <td>-0.910286</td>\n",
       "      <td>-0.537838</td>\n",
       "      <td>0.243541</td>\n",
       "      <td>-0.885329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.279052</td>\n",
       "      <td>-0.972315</td>\n",
       "      <td>0.685374</td>\n",
       "      <td>0.113056</td>\n",
       "      <td>0.238315</td>\n",
       "      <td>0.271913</td>\n",
       "      <td>-0.568816</td>\n",
       "      <td>0.341194</td>\n",
       "      <td>-0.600554</td>\n",
       "      <td>-0.125644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238286</td>\n",
       "      <td>0.809268</td>\n",
       "      <td>0.427521</td>\n",
       "      <td>-0.615932</td>\n",
       "      <td>-0.503697</td>\n",
       "      <td>0.614450</td>\n",
       "      <td>-0.917760</td>\n",
       "      <td>-0.424061</td>\n",
       "      <td>0.185484</td>\n",
       "      <td>-0.580292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      emb_0     emb_1     emb_2     emb_3     emb_4     emb_5     emb_6  \\\n",
       "0 -0.161183 -0.957233 -0.137944  0.050855  0.830055  0.901365 -0.335148   \n",
       "1 -0.523216 -0.974058  0.738608  0.155234  0.626294  0.485297 -0.715657   \n",
       "2 -0.619619 -0.972960 -0.207360 -0.128861  0.044748 -0.387535 -0.730477   \n",
       "3 -0.740843 -0.975749  0.391698  0.641738 -0.268645  0.191745 -0.825593   \n",
       "4 -0.279052 -0.972315  0.685374  0.113056  0.238315  0.271913 -0.568816   \n",
       "\n",
       "      emb_7     emb_8     emb_9  ...   emb_240   emb_241   emb_242   emb_243  \\\n",
       "0 -0.559561 -0.500603  0.165183  ...  0.321248  0.313999  0.636412  0.169179   \n",
       "1 -0.897996 -0.359747  0.398246  ... -0.487843  0.823124  0.412688 -0.338654   \n",
       "2 -0.066126 -0.754899 -0.242004  ...  0.454756  0.473184  0.377866 -0.863887   \n",
       "3 -0.710591 -0.040099 -0.110514  ...  0.271535  0.036040  0.480029 -0.763173   \n",
       "4  0.341194 -0.600554 -0.125644  ...  0.238286  0.809268  0.427521 -0.615932   \n",
       "\n",
       "    emb_244   emb_245   emb_246   emb_247   emb_248   emb_249  \n",
       "0  0.540524 -0.813182  0.286870 -0.231686  0.597416  0.409623  \n",
       "1  0.320787  0.588643 -0.594137  0.182828  0.397090 -0.834364  \n",
       "2 -0.383365  0.137721 -0.810877 -0.447580  0.805932 -0.285284  \n",
       "3  0.022627  0.565165 -0.910286 -0.537838  0.243541 -0.885329  \n",
       "4 -0.503697  0.614450 -0.917760 -0.424061  0.185484 -0.580292  \n",
       "\n",
       "[5 rows x 250 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df = pd.read_pickle(data_path + 'articles_embeddings.pickle')\n",
    "embeddings_df = pd.DataFrame(embeddings_df, columns=[\"emb_\" + str(i) for i in range(embeddings_df.shape[1])])\n",
    "embeddings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 Import fichier avec les interactions des utilisateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_files_clicks(path):\n",
    "    clicks_df = pd.DataFrame()\n",
    "    for file in os.listdir(path):\n",
    "        df = pd.read_csv(path + file)\n",
    "        clicks_df = pd.concat([clicks_df, df], axis=0)\n",
    "\n",
    "    return clicks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks_df = get_all_files_clicks(clicks_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>session_size</th>\n",
       "      <th>click_article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93863</td>\n",
       "      <td>1507865792177843</td>\n",
       "      <td>2</td>\n",
       "      <td>96210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93863</td>\n",
       "      <td>1507865792177843</td>\n",
       "      <td>2</td>\n",
       "      <td>158094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>294036</td>\n",
       "      <td>1507865795185844</td>\n",
       "      <td>2</td>\n",
       "      <td>20691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>294036</td>\n",
       "      <td>1507865795185844</td>\n",
       "      <td>2</td>\n",
       "      <td>96210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77136</td>\n",
       "      <td>1507865796257845</td>\n",
       "      <td>2</td>\n",
       "      <td>336245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id        session_id session_size click_article_id\n",
       "0   93863  1507865792177843            2            96210\n",
       "1   93863  1507865792177843            2           158094\n",
       "2  294036  1507865795185844            2            20691\n",
       "3  294036  1507865795185844            2            96210\n",
       "4   77136  1507865796257845            2           336245"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clicks_df = clicks_df[['user_id', 'session_id', 'session_size', 'click_article_id']]\n",
    "clicks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_article_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[157541, 68866, 96755, 313996, 160158, 233470,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[327984, 183176, 235840, 96663, 59758, 160474,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[119592, 30970, 30760, 209122]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[236444, 234318, 233688, 237452, 235745, 12096...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[336499, 271261, 48915, 44488, 195887, 195084,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          click_article_id\n",
       "user_id                                                   \n",
       "0        [157541, 68866, 96755, 313996, 160158, 233470,...\n",
       "1        [327984, 183176, 235840, 96663, 59758, 160474,...\n",
       "2                           [119592, 30970, 30760, 209122]\n",
       "3        [236444, 234318, 233688, 237452, 235745, 12096...\n",
       "4        [336499, 271261, 48915, 44488, 195887, 195084,..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df = clicks_df.groupby('user_id').agg({'click_article_id':lambda x: list(x)})\n",
    "users_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Content-based Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le **Content-based Filtering** est une méthode de recommandation qui utilise des informations détaillées sur les éléments pour recommander d'autres éléments similaires. Par exemple, dans un système de recommandation de films, le filtrage basé sur le contenu pourrait utiliser des informations telles que le genre du film, le réalisateur, les acteurs, etc.\n",
    "\n",
    "**Principe**\n",
    "L'idée est que si un utilisateur a aimé un certain élément dans le passé, il est probable qu'il aimera à nouveau des éléments similaires à l'avenir. Par conséquent, le système recommande des éléments qui sont similaires aux éléments que l'utilisateur a aimés précédemment.\n",
    "\n",
    "**Calcul de la similarité**\n",
    "La similarité entre les éléments est généralement calculée en utilisant des techniques telles que la similarité cosinus ou la distance euclidienne. Les éléments qui sont les plus similaires à ceux que l'utilisateur a aimés sont recommandés.\n",
    "\n",
    "**Note importante**\n",
    "Il est important de noter que le filtrage basé sur le contenu ne tient pas compte des opinions d'autres utilisateurs. Il se concentre uniquement sur les préférences de l'utilisateur actuel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contentBasedFiltering(articles, clicks, user_id, n=5):\n",
    "    # Get the articles read by the user\n",
    "    articles_read = clicks[clicks['user_id'] == int(user_id)]['click_article_id'].tolist()\n",
    "    print(f\"Articles read by user {user_id}: {articles_read}\")\n",
    "\n",
    "    # If the user hasn't read any articles, recommend the most popular ones\n",
    "    if len(articles_read) == 0:\n",
    "        most_popular_articles = clicks['click_article_id'].value_counts().index.tolist()\n",
    "        print(f\"User {user_id} has not read any articles. Recommending most popular articles: {most_popular_articles[:n]}\")\n",
    "        return most_popular_articles[:n]\n",
    "\n",
    "    # Get the embeddings of the articles read by the user\n",
    "    articles_read_embedding = articles.loc[articles_read]\n",
    "    print(f\"Number of articles read by user {user_id}: {len(articles_read)}\")\n",
    "\n",
    "    # Remove the articles read by the user from the list of articles\n",
    "    articles = articles.drop(articles_read)\n",
    "    print(f\"Remaining articles after removing articles read by user {user_id}: {len(articles)}\")\n",
    "\n",
    "    # Calculate the cosine similarity between the articles read by the user and the other articles\n",
    "    matrix = cosine_similarity(articles_read_embedding, articles)\n",
    "\n",
    "    recommendations = []\n",
    "\n",
    "    # Recommend the articles most similar to the articles read by the user\n",
    "    for i in range(n):\n",
    "        coord_x = floor(np.argmax(matrix)/matrix.shape[1])\n",
    "        coord_y = np.argmax(matrix)%matrix.shape[1]\n",
    "\n",
    "        recommendations.append(int(articles.index[coord_y]))\n",
    "\n",
    "        # Set the similarity of the recommended article to 0\n",
    "        matrix[coord_x][coord_y] = 0\n",
    "\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles read by user 21: [156560, 162655, 303565, 124751, 313504, 140720, 124177, 123757]\n",
      "Number of articles read by user 21: 8\n",
      "Remaining articles after removing articles read by user 21: 364039\n",
      "[123852, 304790, 301782, 304136, 304708]\n"
     ]
    }
   ],
   "source": [
    "# Avec le fichier d'embedding classique\n",
    "test = contentBasedFiltering(embeddings_df, clicks_df, 21)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Collaborative-based Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le **Collaborative-based Filtering** est une méthode de recommandation qui se base sur les comportements passés des utilisateurs pour faire des prédictions sur ce qu'un utilisateur pourrait aimer.\n",
    "\n",
    "**Principe**\n",
    "L'idée principale est que si deux utilisateurs ont eu des comportements similaires par le passé (par exemple, ils ont aimé les mêmes films ou acheté les mêmes produits), alors ils sont susceptibles d'avoir des intérêts similaires à l'avenir.\n",
    "\n",
    "**Types de Filtrage Collaboratif**\n",
    "Il existe deux types principaux de filtrage collaboratif :\n",
    "\n",
    "1. **Filtrage Collaboratif Basé sur les Utilisateurs** : Cette méthode trouve des utilisateurs similaires à l'utilisateur cible et recommande des éléments que ces utilisateurs similaires ont aimés.\n",
    "\n",
    "2. **Filtrage Collaboratif Basé sur les Éléments** : Cette méthode trouve des éléments similaires à ceux que l'utilisateur cible a aimés et recommande ces éléments similaires.\n",
    "\n",
    "3. **Filtrage Collaboratif Basé sur un Modèle** : Cette méthode utilise des techniques de modélisation, comme la factorisation de matrices ou le clustering, pour prédire l'intérêt d'un utilisateur pour un élément. Elle se base sur les comportements passés de tous les utilisateurs, ainsi que sur les évaluations que l'utilisateur cible a données à d'autres éléments.\n",
    "\n",
    "**Calcul de la similarité**\n",
    "La similarité entre les utilisateurs ou les éléments est généralement calculée en utilisant des techniques telles que la corrélation de Pearson ou la similarité cosinus.\n",
    "\n",
    "**Note importante**\n",
    "Contrairement au filtrage basé sur le contenu, le filtrage collaboratif ne nécessite pas d'informations détaillées sur les éléments. Il se base uniquement sur les interactions passées entre les utilisateurs et les éléments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculRatingByClick(clicks):\n",
    "\n",
    "    count_user_article_size = (clicks.groupby(['user_id', \"click_article_id\"]).agg(user_article_size=(\"session_size\", \"sum\")))\n",
    "    count_user_total_size = (clicks.groupby(['user_id']).agg(user_total_size=(\"session_size\", \"sum\")))\n",
    "\n",
    "    ratings = count_user_article_size.join(count_user_total_size, on=\"user_id\")\n",
    "\n",
    "    ratings['rating'] = ratings['user_article_size'] / ratings['user_total_size']\n",
    "\n",
    "    ratings = ratings.reset_index().drop(['user_article_size', 'user_total_size'], axis = 1).rename({'click_article_id': 'article_id'}, axis = 1)\n",
    "\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>68866</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>87205</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>87224</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>96755</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>157541</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  article_id rating\n",
       "0        0       68866  0.125\n",
       "1        0       87205  0.125\n",
       "2        0       87224  0.125\n",
       "3        0       96755  0.125\n",
       "4        0      157541  0.125"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = calculRatingByClick(clicks_df)\n",
    "\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11419393435585924\n",
      "{'n_factors': 20, 'n_epochs': 50, 'lr_all': 0.01, 'reg_all': 0.1}\n"
     ]
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(0, 1))\n",
    "\n",
    "data = Dataset.load_from_df(ratings.sample(frac=0.1, random_state=42), reader=reader)\n",
    "\n",
    "param_grid = {'n_factors': [20, 50, 100], 'n_epochs': [10, 20, 50],\n",
    "              'lr_all': [0.002, 0.005, 0.01], 'reg_all': [0.02, 0.04, 0.1]}\n",
    "\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = gs.best_params['rmse']\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters\n",
    "best_params = gs.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import accuracy\n",
    "\n",
    "def collaborativeFilteringRecommendArticle(articles, ratings, user_id, n=5):\n",
    "    # Convert user_id in ratings DataFrame to string\n",
    "    # ratings['user_id'] = ratings['user_id'].astype(str)\n",
    "    # user_id = str(user_id)\n",
    "\n",
    "    # Create a reader and a data object\n",
    "    reader = Reader(rating_scale=(0, 1))  # ratings range from 0 to 1\n",
    "    data = Dataset.load_from_df(ratings[['user_id', 'article_id', 'rating']], reader)\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "    # Train a SVDpp model\n",
    "    algo = SVD(n_factors=best_params['n_factors'], n_epochs=best_params['n_epochs'], lr_all=best_params['lr_all'], reg_all=best_params['reg_all'])\n",
    "    algo.fit(trainset)\n",
    "\n",
    "    # Predict ratings for the test set\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    # Calculate and print the RMSE\n",
    "    rmse = accuracy.rmse(predictions)\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "\n",
    "    # Calculate and print the MAE\n",
    "    mae = accuracy.mae(predictions)\n",
    "    print(f\"MAE: {mae}\")\n",
    "\n",
    "    # Get the list of articles read by the user\n",
    "    articles_read = ratings[ratings['user_id'] == user_id]['article_id'].tolist()\n",
    "\n",
    "    # Print the number of articles read by the user\n",
    "    print(f\"The user has read {len(articles_read)} articles.\")\n",
    "\n",
    "    # Get the list of all articles\n",
    "    all_articles = list(articles.index)\n",
    "\n",
    "    # Remove the articles already read by the user\n",
    "    articles_to_predict = [article for article in all_articles if article not in articles_read]\n",
    "\n",
    "    # Get the predicted ratings for the articles not yet read by the user\n",
    "    predictions = {article: algo.predict(user_id, str(article)).est for article in articles_to_predict}\n",
    "\n",
    "    # Get the top n articles\n",
    "    top_n_articles = nlargest(n, predictions, key=predictions.get)\n",
    "\n",
    "    return top_n_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from heapq import nlargest\n",
    "\n",
    "def collaborativeFilteringRecommendArticle(articles, ratings, user_id, n=5):\n",
    "    # Create a reader and a data object\n",
    "    reader = Reader(rating_scale=(0, 1))  # ratings range from 0 to 1\n",
    "    data = Dataset.load_from_df(ratings[['user_id', 'article_id', 'rating']], reader)\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "    # Train a SVD model\n",
    "    algo = SVD(n_factors=best_params['n_factors'], n_epochs=best_params['n_epochs'], lr_all=best_params['lr_all'], reg_all=best_params['reg_all'])\n",
    "    algo.fit(trainset)\n",
    "\n",
    "    # Get the list of articles read by the user\n",
    "    articles_read = ratings[ratings['user_id'] == user_id]['article_id'].tolist()\n",
    "\n",
    "    # Get the list of all articles\n",
    "    all_articles = list(articles.index)\n",
    "\n",
    "    # Remove the articles already read by the user\n",
    "    articles_to_predict = [article for article in all_articles if article not in articles_read]\n",
    "\n",
    "    # Get the predicted ratings for the articles not yet read by the user\n",
    "    predictions = {article: algo.predict(user_id, article).est for article in articles_to_predict}\n",
    "\n",
    "    # Get the top n articles\n",
    "    top_n_articles = nlargest(n, predictions, key=predictions.get)\n",
    "\n",
    "    return top_n_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collaborativeFilteringRecommendArticle(articles, clicks, user_id, n=5):\n",
    "\n",
    "    index = list(articles.index)\n",
    "\n",
    "    articles_read = clicks[clicks['user_id'] == user_id]['click_article_id'].tolist()\n",
    "\n",
    "    for ele in articles_read:\n",
    "        if ele in index:\n",
    "            index.remove(ele)\n",
    "\n",
    "    results = dict()\n",
    "\n",
    "    for i in index:\n",
    "        pred = model_SVD.predict(user_id, i)\n",
    "        results[pred.iid] = pred.est\n",
    "    \n",
    "    return nlargest(n, results, key = results.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['article_id', 'rating'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m user_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m21\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m n_recommendations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m----> 4\u001b[0m recommended_articles \u001b[38;5;241m=\u001b[39m \u001b[43mcollaborativeFilteringRecommendArticle\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclicks_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_recommendations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_recommendations\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m recommended articles for user \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecommended_articles\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[44], line 8\u001b[0m, in \u001b[0;36mcollaborativeFilteringRecommendArticle\u001b[0;34m(articles, ratings, user_id, n)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollaborativeFilteringRecommendArticle\u001b[39m(articles, ratings, user_id, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Create a reader and a data object\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     reader \u001b[38;5;241m=\u001b[39m Reader(rating_scale\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# ratings range from 0 to 1\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     data \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mload_from_df(\u001b[43mratings\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marticle_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m, reader)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Split the data into train and test sets\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     trainset, testset \u001b[38;5;241m=\u001b[39m train_test_split(data, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/projet10/lib/python3.11/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/projet10/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/projet10/lib/python3.11/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['article_id', 'rating'] not in index\""
     ]
    }
   ],
   "source": [
    "user_id = '21'\n",
    "n_recommendations = 5\n",
    "\n",
    "recommended_articles = collaborativeFilteringRecommendArticle(embeddings_df, clicks_df, user_id, n_recommendations)\n",
    "\n",
    "print(f\"Top {n_recommendations} recommended articles for user {user_id}: {recommended_articles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x35a4d1e10>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Dataset.load_from_df(ratings, reader=reader)\n",
    "\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "model_SVD = gs.best_estimator['rmse']\n",
    "\n",
    "model_SVD.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def collaborativeFilteringRecommendArticle(articles, clicks, user_id, n=5, evaluate=False):\n",
    "\n",
    "    index = list(articles.index)\n",
    "\n",
    "    articles_read = clicks[clicks['user_id'] == user_id]['click_article_id'].tolist()\n",
    "\n",
    "    for ele in articles_read:\n",
    "        if ele in index:\n",
    "            index.remove(ele)\n",
    "\n",
    "    results = dict()\n",
    "\n",
    "    for i in index:\n",
    "        pred = model_SVD.predict(user_id, i)\n",
    "        results[pred.iid] = pred.est\n",
    "\n",
    "    recommendations = nlargest(n, results, key = results.get)\n",
    "\n",
    "    if evaluate:\n",
    "        # Create a binary list for whether each article was recommended\n",
    "        recommended = [1 if article in recommendations else 0 for article in articles.index]\n",
    "        # Create a binary list for whether each article was read\n",
    "        read = [1 if article in articles_read else 0 for article in articles.index]\n",
    "        # Calculate precision and recall\n",
    "        precision = precision_score(read, recommended)\n",
    "        recall = recall_score(read, recommended)\n",
    "        return recommendations, precision, recall\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(recommended, read, k):\n",
    "    # Only consider top k recommendations\n",
    "    recommended = recommended[:k]\n",
    "    # Calculate precision at k\n",
    "    return sum([1 if article in read else 0 for article in recommended]) / len(recommended)\n",
    "\n",
    "def collaborativeFilteringRecommendArticle(articles, clicks, user_id, n=5, evaluate=False):\n",
    "\n",
    "    index = list(articles.index)\n",
    "\n",
    "    articles_read = clicks[clicks['user_id'] == user_id]['click_article_id'].tolist()\n",
    "\n",
    "    for ele in articles_read:\n",
    "        if ele in index:\n",
    "            index.remove(ele)\n",
    "\n",
    "    results = dict()\n",
    "\n",
    "    for i in index:\n",
    "        pred = model_SVD.predict(user_id, i)\n",
    "        results[pred.iid] = pred.est\n",
    "\n",
    "    recommendations = nlargest(n, results, key = results.get)\n",
    "\n",
    "    if evaluate:\n",
    "        # Calculate precision at k\n",
    "        precision = precision_at_k(recommendations, articles_read, n)\n",
    "        return recommendations, precision\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([289003, 74455, 50644, 39894, 36162], 0.0)\n"
     ]
    }
   ],
   "source": [
    "test_cf = collaborativeFilteringRecommendArticle(embeddings_df,  clicks_df, 5, evaluate=True)\n",
    "print(test_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID: 1\n",
      "Recommended articles: [74455, 289003, 67185, 192263, 283009]\n",
      "Precision at 5: 0.0\n",
      "\n",
      "User ID: 2\n",
      "Recommended articles: [36193, 289003, 42270, 163686, 74457]\n",
      "Precision at 5: 0.0\n",
      "\n",
      "User ID: 3\n",
      "Recommended articles: [289003, 74455, 283009, 277107, 50644]\n",
      "Precision at 5: 0.0\n",
      "\n",
      "User ID: 4\n",
      "Recommended articles: [316504, 74455, 289003, 213668, 36193]\n",
      "Precision at 5: 0.0\n",
      "\n",
      "User ID: 5\n",
      "Recommended articles: [289003, 74455, 50644, 39894, 36162]\n",
      "Precision at 5: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace these with actual user_ids\n",
    "user_ids = [1, 2, 3, 4, 5]\n",
    "\n",
    "for user_id in user_ids:\n",
    "    recommendations, precision = collaborativeFilteringRecommendArticle(embeddings_df, clicks_df, user_id, n=5, evaluate=True)\n",
    "    print(f\"User ID: {user_id}\")\n",
    "    print(f\"Recommended articles: {recommendations}\")\n",
    "    print(f\"Precision at 5: {precision}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
